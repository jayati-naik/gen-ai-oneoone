{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user output\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class TestCase(BaseModel):\n",
    "    description: str = Field(description=\"Test case description\")\n",
    "    function_name: str = Field(description=\"Function name this test case is covering\")\n",
    "    input: str = Field(description=\"Input to the test case\")\n",
    "    output: str = Field(description=\"expected correct output to the testcase\")\n",
    "    number_of_lines_per_testcase: int = Field(description=\"Return number of lines covered with this testcase\")\n",
    "    \n",
    "\n",
    "class TestCaseDetails(BaseModel):\n",
    "    '''\n",
    "    This class will define the output.\n",
    "    Output will have No of Test cases needed to cover 90% test coverage\n",
    "    And description for each testcase\n",
    "    '''\n",
    "    num_test_cases: int = Field(description=\"Return No of Test cases for all the methods in uploaded file\")\n",
    "    test_case: list[TestCase] = Field(description=\"Write description for each sceanrio with function name this test case is covering in scala file passed as prompt\")\n",
    "    code_coverage: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"Code coverage should be greater then or equal to 90%\", allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "    #Field(description=\"Return code coverage for current file in percentage\")\n",
    "    list_function_names: str = Field(description=\"list of all function names to be tested. Make the list comma seperated\")\n",
    "    \n",
    "    '''\n",
    "    test_cases: str = Field(description=\"Generate testcases in the language of the uploaded file for 90% coverage\")\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/jayatinaik/Projects/gen-ai-oneoone/scala_test_generator/reosurces/Huffman.scala\") as f:\n",
    "    scala_code = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = f\"Take the input scala class and generate no of test cases required to cover 90% test cases and description of each test case\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is incomplete due to a max_tokens length limit.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "try:\n",
    "    tester = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=TestCaseDetails,\n",
    "        max_retries = 3,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"system\", \"content\": f\"Parse the code and generate testcases from: {scala_code}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(tester.model_dump_json(indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
